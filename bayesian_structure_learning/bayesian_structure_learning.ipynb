{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bb9b46",
   "metadata": {},
   "source": [
    "# Bayesian structure learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739eeb7",
   "metadata": {},
   "source": [
    "Here we perform UQ for a GFlowNets trained to sample candidate graphs for a linear Gaussian network using PCE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d7a7f",
   "metadata": {},
   "source": [
    "First, we import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2fdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from pgmpy.models import LinearGaussianBayesianNetwork\n",
    "from jax import vmap\n",
    "import logging\n",
    "import matplotlib\n",
    "logging.getLogger('matplotlib.category').setLevel('WARNING')\n",
    "import chaospy as chaos\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn import linear_model as lm\n",
    "from numpy.random import default_rng\n",
    "sns.set(font='Times New Roman', style = 'white')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dag_gflownet.utils.factories import get_scorer\n",
    "from dag_gflownet.scores.bge_score import BGeScore\n",
    "from dag_gflownet.scores.priors import UniformPrior\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07451170",
   "metadata": {},
   "source": [
    "We can import the 250/500 datasets used to train the GFN, and use this to find a low-dimensional embedding using PCA. We approximate this low-dimensional space with a mean-zero Gaussian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d92fcc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m,no_models):\n\u001b[32m     17\u001b[39m     var_names = [\u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mE\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     df = pd.DataFrame(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m, columns=var_names)\n\u001b[32m     19\u001b[39m     scorer = BGeScore(data=df, prior=prior)\n\u001b[32m     20\u001b[39m     r_matrices.append(scorer.R)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "no_models = 250\n",
    "\n",
    "for n in range(0,no_models):\n",
    "    try:\n",
    "        data.append(pd.read_csv(f'output/data{n}.csv', index_col=0))\n",
    "    except: print(n)\n",
    "\n",
    "prior = UniformPrior()\n",
    "\n",
    "r_matrices = []\n",
    "r_vectors = []\n",
    "\n",
    "for n in range(0,no_models):\n",
    "\n",
    "    var_names = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    df = pd.DataFrame(data[n], columns=var_names)\n",
    "    scorer = BGeScore(data=df, prior=prior)\n",
    "    r_matrices.append(scorer.R)\n",
    "    r_vectors.append(scorer.R.flatten())\n",
    "r_vectors = np.array(r_vectors)\n",
    "\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "r_scaled  = scaler.fit_transform(r_vectors)\n",
    "r_vectors_pca = pca.fit_transform(r_scaled)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(3,3)\n",
    "\n",
    "ax.scatter(r_vectors_pca[:,0],r_vectors_pca[:,1], s = 10, color = 'k',alpha = 0.5)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "x_mean, y_mean = np.mean(r_vectors_pca,0)\n",
    "Sigma = np.cov(r_vectors_pca.T)\n",
    "print('Gaussian approximation of latent space')\n",
    "print(x_mean, y_mean)\n",
    "print(np.diag(np.diag(Sigma))) # keep only diagonal covariance (ind.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906365c8",
   "metadata": {},
   "source": [
    "We import the *true* underlying graph for the linear Gaussian network,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f7b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"graph.pkl\", \"rb\") as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e2ed8",
   "metadata": {},
   "source": [
    "and the 250 GFNs in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d22d65d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m,\u001b[32m250\u001b[39m):\n\u001b[32m      5\u001b[39m     prior = UniformPrior()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     scorer = BGeScore(data=\u001b[43mdata\u001b[49m[n], prior=prior)\n\u001b[32m      7\u001b[39m     env = GFlowNetDAGEnv(num_envs=\u001b[32m1\u001b[39m, scorer=scorer)\n\u001b[32m      8\u001b[39m     replay = ReplayBuffer(capacity=\u001b[32m1\u001b[39m, num_variables=env.num_variables)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "params = []\n",
    "for n in range(0,250):\n",
    "\n",
    "    prior = UniformPrior()\n",
    "    scorer = BGeScore(data=data[n], prior=prior)\n",
    "    env = GFlowNetDAGEnv(num_envs=1, scorer=scorer)\n",
    "    replay = ReplayBuffer(capacity=1, num_variables=env.num_variables)\n",
    "    gflownet = DAGGFlowNet()\n",
    "    optimizer = optax.adam(1e-4)\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    params_scaffold, state = gflownet.init(\n",
    "        key,\n",
    "        optimizer,\n",
    "        replay.dummy['adjacency'],\n",
    "        replay.dummy['mask']\n",
    "    )\n",
    "    loaded_data = io.load('output/model'+ str(n) + '.npz')\n",
    "    loaded_online_params = loaded_data['params']\n",
    "    reconstructed_params = params_scaffold._replace(online=loaded_online_params)\n",
    "\n",
    "    params.append(reconstructed_params)\n",
    "    models.append(gflownet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ed6f8",
   "metadata": {},
   "source": [
    "We construct a 'trajectory' in this case which puts together the ground truth graph, and converts it into a list of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c193801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy_distribution(gflownet_agent, params, observations):\n",
    "    log_pi = vmap(gflownet_agent.model.apply, in_axes=(None, 0, 0))(\n",
    "        params, observations['adjacency'], observations['mask']\n",
    "    )\n",
    "    return jnp.exp(log_pi)\n",
    "\n",
    "def sample_action_manually(gflownet_agent, params, key, observations):\n",
    "    policy_probs = get_policy_distribution(gflownet_agent, params, observations)[0]\n",
    "\n",
    "    mask = observations['mask'][0].flatten()\n",
    "\n",
    "    full_mask = jnp.concatenate([mask, jnp.array([1.])])\n",
    "    \n",
    "    masked_probs = policy_probs * full_mask\n",
    "    final_probs = masked_probs / jnp.sum(masked_probs)\n",
    "\n",
    "    action = jax.random.choice(key, a=len(final_probs), p=final_probs)\n",
    "    return jnp.array([action])\n",
    "\n",
    "def action_to_edge(action):\n",
    "    source = action // num_variables\n",
    "    target = action % num_variables\n",
    "    return (source,target)\n",
    "\n",
    "def edge_to_actions(source,target,num_variables=5):return source*num_variables+target\n",
    "\n",
    "list_of_edges = graph.edges()\n",
    "\n",
    "num_variables = len(graph.nodes())\n",
    "\n",
    "node_to_int = {node: i for i, node in enumerate(graph.nodes())}\n",
    "\n",
    "action_sequence = [\n",
    "    node_to_int[source] * num_variables + node_to_int[target]\n",
    "    for source, target in list_of_edges\n",
    "]\n",
    "\n",
    "stop_action = num_variables * num_variables\n",
    "action_sequence.append(stop_action)\n",
    "\n",
    "print(f\"Ground-Truth Graph: {list_of_edges}\")\n",
    "print(f\"Actions: {action_sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713ec3d",
   "metadata": {},
   "source": [
    "From each of the 250 models, we extract the policy along this trajectory. We also use the logit transform to turn probabilities into real-numbers which can modelled by polynomials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = []\n",
    "\n",
    "for j, model in enumerate(models):\n",
    "\n",
    "    policy_trajectory = []\n",
    "    observations = env.reset()\n",
    "\n",
    "    for i, action in enumerate(action_sequence):\n",
    "        current_policy = get_policy_distribution(\n",
    "            model, params[j].online, observations\n",
    "        )[0]\n",
    "        \n",
    "        policy_trajectory.append(np.array(current_policy,dtype=np.float64))\n",
    "\n",
    "        observations, _, _, _ = env.step(np.array([action]))\n",
    "    \n",
    "    policies.append(policy_trajectory)\n",
    "\n",
    "policies = np.array(policies)\n",
    "\n",
    "def logit(y):\n",
    "    return np.log(y/(1-y))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "epsilon = 1e-10\n",
    "A_safe = np.where(policies == 0, epsilon, policies)\n",
    "logit_ensemble_policy = logit(A_safe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd15f9",
   "metadata": {},
   "source": [
    "Next, we construct an orthonormal polynomial basis, with respect to the Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 7\n",
    "\n",
    "q0, q1 = chaos.numpoly.variable(2)\n",
    "\n",
    "hermite_1 = chaos.expansion.hermite(degree, mu=0, sigma=np.sqrt(Sigma[0,0]),normed=False)\n",
    "hermite_2 = chaos.expansion.hermite(degree, mu=0, sigma=np.sqrt(Sigma[1,1]),normed=False)\n",
    "\n",
    "hermite1 = hermite_1(q0)\n",
    "hermite2 = hermite_2(q1)\n",
    "\n",
    "outer_product_basis = chaos.outer(hermite1, hermite2).flatten()\n",
    "polynomial_basis = outer_product_basis[np.sum(outer_product_basis.exponents, axis=1) <= degree]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e7c93",
   "metadata": {},
   "source": [
    "We then fit the coefficients using ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_models = []\n",
    "all_zeros = []\n",
    "\n",
    "for i in range(0,logit_ensemble_policy.shape[1]):\n",
    "\n",
    "    models_step_i = []\n",
    "\n",
    "    for j in range(0,logit_ensemble_policy.shape[2]):\n",
    "        fitted_polynomial = chaos.fit_regression(\n",
    "                polynomial_basis, r_vectors_pca.T, logit_ensemble_policy[:,i,j], model=lm.Ridge(fit_intercept=False))\n",
    "        if np.all(policies[:,i,j]==0):\n",
    "            all_zeros.append((i,j))\n",
    "\n",
    "        models_step_i.append(fitted_polynomial)\n",
    "\n",
    "    polynomial_models.append(models_step_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ea9b8",
   "metadata": {},
   "source": [
    "To generate new outputs from our surrogate model, we have to sample new datasets from the linear Gaussian network, project these into the latent space using PCA, then plug these inputs into the PCE. Model outputs are then transformed into probability distributions with the softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_linear_gaussian(model, num_samples, rng=None):\n",
    "    if not isinstance(model, LinearGaussianBayesianNetwork):\n",
    "        raise ValueError('The model must be an instance of LinearGaussianBayesianNetwork')\n",
    "    \n",
    "    if rng is None:\n",
    "        rng = default_rng()\n",
    "    \n",
    "    samples = pd.DataFrame(index=range(num_samples), columns=list(model.nodes()), dtype=float)\n",
    "    \n",
    "    for node in nx.topological_sort(model):\n",
    "        cpd = model.get_cpds(node)\n",
    "        \n",
    "        if cpd.evidence:\n",
    "            parent_values = samples[cpd.evidence].to_numpy()  # shape (num_samples, num_parents)\n",
    "            intercept = cpd.beta[0]\n",
    "            coefficients = np.array(cpd.beta[1:])\n",
    "            mean = intercept + np.dot(parent_values, coefficients)\n",
    "            samples[node] = rng.normal(loc=mean, scale=cpd.std)\n",
    "        else:\n",
    "            intercept = cpd.beta[0]\n",
    "            mean = np.full(num_samples, intercept)\n",
    "            samples[node] = rng.normal(loc=mean, scale=cpd.std)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "data_samples = []\n",
    "data_scorers = []\n",
    "r_matrices = []\n",
    "r_vectors = []\n",
    "\n",
    "prior = UniformPrior()\n",
    "no_datasets = 10000\n",
    "no_samples = 100\n",
    "\n",
    "for n in range(0,no_datasets):\n",
    "    samples = sample_from_linear_gaussian(graph, no_samples)\n",
    "    data_samples.append(data_samples)\n",
    "    \n",
    "    var_names = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    df = pd.DataFrame(samples, columns=var_names)\n",
    "    scorer = BGeScore(data=df, prior=prior)\n",
    "    data_scorers.append(scorer)\n",
    "\n",
    "    r_matrices.append(scorer.R)\n",
    "    r_vectors.append(scorer.R.flatten())\n",
    "r_vectors = np.array(r_vectors)\n",
    "\n",
    "n_components = 2\n",
    "pca = PCA(n_components=n_components)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "r_scaled  = scaler.fit_transform(r_vectors)\n",
    "r_vectors_pca_inputs = pca.fit_transform(r_scaled)\n",
    "\n",
    "outputs = np.zeros((no_datasets,7,26))\n",
    "prob_output_softmax = np.zeros((no_datasets,7,26))\n",
    "\n",
    "for i in range(0,7):\n",
    "    for j in range(0,26):\n",
    "        outputs[:,i,j] = polynomial_models[i][j](*r_vectors_pca_inputs.T)\n",
    "        if (i,j) in all_zeros:\n",
    "            outputs[:,i,j] = - np.inf\n",
    "    prob_output_softmax[:,i,:] = softmax(outputs[:,i,:],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb6539",
   "metadata": {},
   "source": [
    "We want to compare these outputs to a testing ensemble of models that was not used in the fitting of the PCE,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eabdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "no_models = 250\n",
    "\n",
    "for n in range(250,250+no_models):\n",
    "    try:\n",
    "        test_data.append(pd.read_csv(f'output/data{n}.csv', index_col=0))\n",
    "    except: print(n)\n",
    "\n",
    "test_models = []\n",
    "test_params = []\n",
    "\n",
    "for n in range(250,500):\n",
    "\n",
    "    prior = UniformPrior()\n",
    "    scorer = BGeScore(data=test_data[n-250], prior=prior)\n",
    "    env = GFlowNetDAGEnv(num_envs=1, scorer=scorer)\n",
    "    replay = ReplayBuffer(capacity=1, num_variables=env.num_variables)\n",
    "    gflownet = DAGGFlowNet()\n",
    "    optimizer = optax.adam(1e-4)\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    params_scaffold, state = gflownet.init(\n",
    "        key,\n",
    "        optimizer,\n",
    "        replay.dummy['adjacency'],\n",
    "        replay.dummy['mask']\n",
    "    )\n",
    "    loaded_data = io.load('output/model'+ str(n) + '.npz')\n",
    "    loaded_online_params = loaded_data['params']\n",
    "    reconstructed_params = params_scaffold._replace(online=loaded_online_params)\n",
    "\n",
    "    test_params.append(reconstructed_params)\n",
    "    test_models.append(gflownet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3534925",
   "metadata": {},
   "source": [
    "and then extract the policies along this same specified trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56881ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_policies = []\n",
    "\n",
    "for j, model in enumerate(test_models):\n",
    "\n",
    "    policy_trajectory = []\n",
    "    observations = env.reset()\n",
    "\n",
    "    for i, action in enumerate(action_sequence):\n",
    "        current_policy = get_policy_distribution(\n",
    "            model, test_params[j].online, observations\n",
    "        )[0]\n",
    "        \n",
    "        policy_trajectory.append(np.array(current_policy,dtype=np.float64))\n",
    "\n",
    "        observations, _, _, _ = env.step(np.array([action]))\n",
    "    \n",
    "    test_policies.append(policy_trajectory)\n",
    "\n",
    "test_policies = np.array(test_policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17230e",
   "metadata": {},
   "source": [
    "We can then plot the surrogate model against the testing policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(18, 9))\n",
    "\n",
    "ax[0, 0].axis(\"off\")\n",
    "\n",
    "for n in range(7):\n",
    "    idx = n + 1\n",
    "    i = idx // 4\n",
    "    j = idx % 4\n",
    "\n",
    "    data_n = test_policies[:, n, :]\n",
    "    surrogate_n = prob_output_softmax[:, n, :]\n",
    "\n",
    "    df_emp = pd.DataFrame(data_n)\n",
    "    df_emp = df_emp.melt(var_name=\"Action\", value_name=\"Probability\")\n",
    "    df_emp[\"Source\"] = \"Empirical\"\n",
    "\n",
    "    df_sur = pd.DataFrame(surrogate_n)\n",
    "    df_sur = df_sur.melt(var_name=\"Action\", value_name=\"Probability\")\n",
    "    df_sur[\"Source\"] = \"Surrogate\"\n",
    "\n",
    "    df_all = pd.concat([df_emp, df_sur], ignore_index=True)\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=df_all, x=\"Action\", y=\"Probability\", hue=\"Source\",\n",
    "        showcaps=True, showfliers=False, dodge=True,\n",
    "        palette={\"Empirical\": \"darkorange\", \"Surrogate\": \"teal\"},\n",
    "        ax=ax[i, j]\n",
    "    )\n",
    "\n",
    "    ax[i, j].tick_params(axis=\"x\", rotation=90)\n",
    "    ax[i, j].set_title(f\"Policy at Step {n+1}\")\n",
    "    ax[i, j].set_xlabel(\"Action Index\")\n",
    "    ax[i, j].set_ylabel(\"Probability\")\n",
    "\n",
    "    ax[i, j].axvline(action_sequence[n], color=\"grey\", linestyle=\"dotted\")\n",
    "\n",
    "    if n == 0: \n",
    "        ax[i, j].legend(loc=\"lower right\")\n",
    "    else:\n",
    "        ax[i, j].get_legend().remove()\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d3e2b",
   "metadata": {},
   "source": [
    "## Comparison to a multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a0767",
   "metadata": {},
   "source": [
    "We compare our PCE surrogate model to a MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4954b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPolicy(nn.Module):\n",
    "    def __init__(self, hidden_sizes=[64, 64], num_actions=26):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        input_dim = 2\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = h\n",
    "        layers.append(nn.Linear(input_dim, num_actions))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x)\n",
    "        probs = F.softmax(logits, dim=-1)  \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4dca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(0,7):\n",
    "    print(i)\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(r_vectors_pca, dtype=torch.float32),\n",
    "    torch.tensor(policies[:, i, :], dtype=torch.float32)\n",
    ")\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = MLPPolicy()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        for xb, yb in dataloader:\n",
    "            pred = model(xb)               # [batch, 26]\n",
    "            loss = F.kl_div(pred.log(), yb, reduction=\"batchmean\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch {epoch}, loss = {loss.item():.4f}\")\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6853515",
   "metadata": {},
   "source": [
    "We then evaluate it on the same inputs as the PCE surrogate model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c74803",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.zeros((no_datasets, 7, 26), dtype=np.float32)\n",
    "\n",
    "for i in range(0,7):\n",
    "    model = models[i]\n",
    "    with torch.no_grad():\n",
    "        preds = model(torch.tensor(r_vectors_pca_inputs, dtype=torch.float32))\n",
    "    outputs[:, i, :] = preds.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168fd7a",
   "metadata": {},
   "source": [
    "and plot the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(18, 9))\n",
    "\n",
    "ax[1, 3].axis(\"off\")\n",
    "\n",
    "for n in range(7):\n",
    "    idx = n\n",
    "    i = idx // 4\n",
    "    j = idx % 4\n",
    "\n",
    "    data_n = test_policies[:, n, :]\n",
    "    mlp_n = mlp_outputs[:, n, :]\n",
    "    surrogate_n = prob_output_softmax[:, n, :]\n",
    "\n",
    "    df_emp = pd.DataFrame(data_n)\n",
    "    df_emp = df_emp.melt(var_name=\"Action\", value_name=\"Probability\")\n",
    "    df_emp[\"Source\"] = \"Empirical\"\n",
    "\n",
    "    df_mlp = pd.DataFrame(mlp_n)\n",
    "    df_mlp = df_mlp.melt(var_name=\"Action\", value_name=\"Probability\")\n",
    "    df_mlp[\"Source\"] = \"MLP\"\n",
    "\n",
    "    df_sur = pd.DataFrame(surrogate_n)\n",
    "    df_sur = df_sur.melt(var_name=\"Action\", value_name=\"Probability\")\n",
    "    df_sur[\"Source\"] = \"PCE\"\n",
    "\n",
    "    df_all = pd.concat([df_emp, df_mlp, df_sur], ignore_index=True)\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=df_all, x=\"Action\", y=\"Probability\", hue=\"Source\",\n",
    "        showcaps=True, showfliers=False, dodge=True,\n",
    "        palette={\"Empirical\": \"darkorange\", \"MLP\": \"orchid\", \"PCE\": \"teal\"},\n",
    "        ax=ax[i, j]\n",
    "    )\n",
    "\n",
    "    ax[i, j].tick_params(axis=\"x\", rotation=90)\n",
    "    ax[i, j].set_title(f\"Policy at Step {n+1}\")\n",
    "    ax[i, j].set_xlabel(\"Action Index\")\n",
    "    ax[i, j].set_ylabel(\"Probability\")\n",
    "\n",
    "    ax[i, j].axvline(action_sequence[n], color=\"grey\", linestyle=\"dotted\")\n",
    "\n",
    "    if n == 0:\n",
    "        ax[i, j].legend(loc=\"lower right\")\n",
    "    else:\n",
    "        ax[i, j].get_legend().remove()\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
